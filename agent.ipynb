{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c13cdf",
   "metadata": {},
   "source": [
    "## Agent \n",
    "Quesqu'un **agent IA**\n",
    "\n",
    "  Les **agents d'IA** sont des systèmes logiciels qui utilisent l'IA pour atteindre des objectifs et effectuer des tâches au nom des utilisateurs. Ils font preuve de raisonnement, de planification et de mémoire, et disposent d'un certain niveau d'autonomie pour prendre des décisions, apprendre et s'adapter.\n",
    "\n",
    "  Leurs capacités sont en grande partie rendues possibles par la **capacité multimodale** de **l'IA générative** et des modèles de fondation d'IA. Les agents d'IA peuvent traiter simultanément des informations multimodales telles que du texte, de la voix, des vidéos, des sons, du code, etc. Ils peuvent converser, raisonner, apprendre et prendre des décisions. Ils peuvent apprendre au fil du temps et faciliter les transactions et les processus métier. Les agents peuvent collaborer avec d'autres agents pour coordonner et exécuter des workflows plus complexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6115125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain import hub\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from pprint import pprint\n",
    "\n",
    "# Chargement des clés d'API se trouvant dans le fichier .env.  \n",
    "# Ceci permet d'utiliser des modèles en ligne comme gpt-x, deepseek-x, etc...\n",
    "load_dotenv(override=True)\n",
    "\n",
    "#model = ChatOllama(model=\"llama3\", temperature=0)\n",
    "model = ChatDeepSeek(model=\"deepseek-chat\", api_key=os.getenv(\"DEEPSEEK_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eda05d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparation des outils\n",
    "def data_right_disability(query):\n",
    "    message =\"Voici les droits sur les handicapées\"\n",
    "    return message\n",
    "\n",
    "def data_right_child(query):\n",
    "    message =\"Voici les droits sur les enfants\"\n",
    "    return message\n",
    "\n",
    "def data_right_accommodation(query):\n",
    "    message =\"Voici les droits sur les logements\"\n",
    "    return message\n",
    "\n",
    "def error_handle_message(query):\n",
    "    message =f\"Je n'ai pas compris la requête veuillez reformuler votre message '{query}'\"\n",
    "    return \"Je n'ai pas compris la requête veuillez reformuler votre message\"\n",
    "\n",
    "tools=[\n",
    "    Tool(\n",
    "        name=\"right_disability\",\n",
    "        func=data_right_disability,\n",
    "        description=\"\"\"\n",
    "        Use this tool if the query is asking right,help,service about disability stay polite and helpful.\n",
    "        If it's french right use the data documentary if possible if not use internet.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"right_child\",\n",
    "        func=data_right_child,\n",
    "        description=\"\"\"\n",
    "        Use this tool if the query is asking right,help,service about children stay polite and helpful.\n",
    "        If it's french right use the data documentary if possible if not use internet.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"right_accommodation\",\n",
    "        func=data_right_accommodation,\n",
    "        description=\"\"\"\n",
    "        Use this tool if the query is asking right,help,service about accomodation stay polite and helpful.\n",
    "        If it's french right use the data documentary if possible if not use internet.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"generate_message\",\n",
    "        func=error_handle_message,\n",
    "        description=\"\"\"\n",
    "        Use this tool if the query is not right about disability, child or accommodation and quit ask to rewrite\n",
    "        the question. If it's unclearn but it's to much unclear query quit the conversation and stay polite\"\"\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5844d7fc",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac273df",
   "metadata": {},
   "source": [
    "le choix ce porte pour **rlm/rag-prompt** car il est plus adapter pour le chat les question/réponse.\n",
    "\n",
    "\n",
    "  source : https://smith.langchain.com/hub/rlm/rag-prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b315fc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\simplon dev\\python\\W9\\ai-agent-with-langchain\\.venv\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Prompt missing required variables: {'tool_names', 'tools', 'agent_scratchpad'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m memory= ConversationBufferMemory(memory_key=\u001b[33m\"\u001b[39m\u001b[33mchat_history\u001b[39m\u001b[33m\"\u001b[39m, return_messages=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#creation agent\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m agent=\u001b[43mcreate_react_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstop_sequence\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#encapsulation agent\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#enlever dans la version final mettre Verbose a false\u001b[39;00m\n\u001b[32m     17\u001b[39m executor=AgentExecutor.from_agent_and_tools( \n\u001b[32m     18\u001b[39m     agent=agent,\n\u001b[32m     19\u001b[39m     tools=tools,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     handle_parsing_errors=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     24\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\simplon dev\\python\\W9\\ai-agent-with-langchain\\.venv\\Lib\\site-packages\\langchain\\agents\\react\\agent.py:124\u001b[39m, in \u001b[36mcreate_react_agent\u001b[39m\u001b[34m(llm, tools, prompt, output_parser, tools_renderer, stop_sequence)\u001b[39m\n\u001b[32m    120\u001b[39m missing_vars = {\u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtool_names\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33magent_scratchpad\u001b[39m\u001b[33m\"\u001b[39m}.difference(\n\u001b[32m    121\u001b[39m     prompt.input_variables + \u001b[38;5;28mlist\u001b[39m(prompt.partial_variables)\n\u001b[32m    122\u001b[39m )\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_vars:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrompt missing required variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    126\u001b[39m prompt = prompt.partial(\n\u001b[32m    127\u001b[39m     tools=tools_renderer(\u001b[38;5;28mlist\u001b[39m(tools)),\n\u001b[32m    128\u001b[39m     tool_names=\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([t.name \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools]),\n\u001b[32m    129\u001b[39m )\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stop_sequence:\n",
      "\u001b[31mValueError\u001b[39m: Prompt missing required variables: {'tool_names', 'tools', 'agent_scratchpad'}"
     ]
    }
   ],
   "source": [
    "# Chargement du prompt standard pour le paradigme ReAct depuis LangChain Hub\n",
    "#prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "# Initialisation de la mémoire pour suivre l’historique des échanges\n",
    "memory= ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "#creation agent\n",
    "agent=create_react_agent(\n",
    "    llm=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    "    stop_sequence=True\n",
    "    \n",
    ")\n",
    "\n",
    "#encapsulation agent\n",
    "#enlever dans la version final mettre Verbose a false\n",
    "executor=AgentExecutor.from_agent_and_tools( \n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    max_iterations=5,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f20e55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Vous :** quit"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de la conversation.\n"
     ]
    }
   ],
   "source": [
    "# Boucle interactive terminale\n",
    "while True:\n",
    "    user_input = input(\"Vous : \")\n",
    "    clear_output(wait=True)                         # Efface l'affichage précédent\n",
    "    display(Markdown(f\"**Vous :** {user_input}\"))   # Affiche la requête de l'utilisateur\n",
    "\n",
    "    if user_input.lower() in [\"stop\", \"exit\", \"quit\"]:\n",
    "        print(\"Fin de la conversation.\")\n",
    "        break\n",
    "\n",
    "    response = executor.invoke({\"input\": user_input})\n",
    "    display(Markdown(response[\"output\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
